{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE THE MODEL IS TRAINED ONLY FOR URBAN IMAGES!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = \"cuda\" # Use this if you have install the cuda version of torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COLORIZATION CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorizationAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define the architecture\n",
    "        self.down1 = nn.Conv2d(1, 64, 3, stride=2, padding=1)\n",
    "        self.down2 = nn.Conv2d(64, 128, 3, stride=2, padding=1)\n",
    "        self.down3 = nn.Conv2d(128, 256, 3, stride=2, padding=1)\n",
    "        self.down4 = nn.Conv2d(256, 512, 3, stride=2, padding=1)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, output_padding=1)\n",
    "        self.up2 = nn.ConvTranspose2d(512, 128, 3, stride=2, padding=1, output_padding=1)\n",
    "        self.up3 = nn.ConvTranspose2d(256, 64, 3, stride=2, padding=1, output_padding=1)\n",
    "        self.up4 = nn.ConvTranspose2d(128, 3, 3, stride=2, padding=1, output_padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Downsample\n",
    "        d1 = self.relu(self.down1(x))\n",
    "        d2 = self.relu(self.down2(d1))\n",
    "        d3 = self.relu(self.down3(d2))\n",
    "        d4 = self.relu(self.down4(d3))\n",
    "        \n",
    "        # Upsample\n",
    "        u1 = self.relu(self.up1(d4))\n",
    "        u2 = self.relu(self.up2(torch.cat((u1, d3), dim=1)))\n",
    "        u3 = self.relu(self.up3(torch.cat((u2, d2), dim=1)))\n",
    "        u4 = self.sigmoid(self.up4(torch.cat((u3, d1), dim=1)))\n",
    "        return u4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTION TO LOAD AND PREPROSSES THE GRAYSCALE IMAGE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    \n",
    "    image = Image.open(image_path).convert('L')   # Loading of the grayscale image \n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),  \n",
    "        transforms.ToTensor(),         \n",
    "        transforms.Normalize((0.5,), (0.5,))  \n",
    "    ])\n",
    "    image = transform(image).unsqueeze(0) \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTION TO POST - PROCESS THE MODEL OUTPUT AND DISPLAY THE IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_and_save(output, save_path):\n",
    "    output = output.squeeze(0).permute(1, 2, 0) \n",
    "    output = output.detach().cpu().numpy()  \n",
    "    output = (output * 255).astype(np.uint8)  \n",
    "    \n",
    "    colorized_image = Image.fromarray(output)\n",
    "    colorized_image.save(save_path)  \n",
    "    \n",
    "    plt.imshow(output)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING THE INSTANCE OF THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ColorizationAutoencoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(r'path_to_the_save_Model')) # Enter the path where your model is saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATION MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOVING MODEL TO GPU/CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTION TO COLOURIZE THE IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize_image(image_path, save_path):\n",
    "    grayscale_img = preprocess_image(image_path).to(device)  # Preprocess and send to to CPU or GPU if available\n",
    "    with torch.no_grad():\n",
    "        colorized_img = model(grayscale_img)  \n",
    "    postprocess_and_save(colorized_img, save_path)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPECIFYING THE PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path =r\"path_to_your_grayscale_image\" # Enter the path of the image which you want to color\n",
    "save_path = 'colorized_image.png'\n",
    "colorize_image(image_path, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srgans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
